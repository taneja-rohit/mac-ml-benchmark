{
  "benchmark": "mlx_lora_finetuning",
  "model": "mlx-community/Mistral-7B-Instruct-v0.2-4bit",
  "precision": "4-bit quantized",
  "trainable_params": 10486000,
  "trainable_percent": 0.145,
  "total_params": 7241732000,
  "iters": 50,
  "batch_size": 1,
  "tokens_per_second_avg": 210,
  "tokens_per_second_range": "195-217",
  "peak_memory_gb": 7.614,
  "start_val_loss": 1.362,
  "final_val_loss": 1.064,
  "final_train_loss": 1.102,
  "timestamp": "2026-01-22T23:45:00"
}
